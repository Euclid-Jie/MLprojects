{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re # 正则表达式库\n",
    "import pandas as pd\n",
    "import collections # 词频统计库\n",
    "import numpy as np # numpy数据处理库\n",
    "import jieba # 结巴分词\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 读取每章内容，先进行分词，去掉停用词（参考cn_stopwords.txt），对每章的词频进行统计；"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#读取中共简史文件夹下所有文件的名称\n",
    "dirpath = r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\2022-06-机器学习期末大作业\\中国共产党简史'\n",
    "fileslist = os.listdir(dirpath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 创建停用词列表\n",
    "def stopwordslist():\n",
    "    stopwords = [line.strip() for line in open(r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\2022-06-机器学习期末大作业\\cn_stopwords.txt',encoding='UTF-8').readlines()]\n",
    "    return stopwords"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理共产党简史第1章的文本内容\n",
      "已读取'1.1.近代中华民族的历史任务和辛亥革命.txt'文件内容\n",
      "已读取'1.2.五四运动和马克思主义的传播.txt'文件内容\n",
      "已读取'1.3.中国共产党的成立和民主革命纲领的制定.txt'文件内容\n",
      "已读取'1.4.第一次国共合作和大革命的兴起.txt'文件内容\n",
      "已读取'1.5.北伐战争的胜利进军和大革命的失败.txt'文件内容\n",
      "第1章词频统计文件已保存\n",
      "开始处理共产党简史第2章的文本内容\n",
      "已读取'2.1.从南昌起义到井冈山革命根据地的创建.txt'文件内容\n",
      "已读取'2.2.革命运动的复兴和红军反“围剿”的胜利.txt'文件内容\n",
      "已读取'2.3.王明“左”倾错误和革命运动的挫折.txt'文件内容\n",
      "已读取'2.4.遵义会议的伟大转折和红军长征的胜利.txt'文件内容\n",
      "已读取'2.5.为建立抗日民族统一战线而斗争.txt'文件内容\n",
      "第2章词频统计文件已保存\n",
      "开始处理共产党简史第3章的文本内容\n",
      "已读取'3.1.抗日民族统一战线形成和全面抗战路线的制定.txt'文件内容\n",
      "已读取'3.2.敌后战场的开辟和统一战线中的独立自主原则.txt'文件内容\n",
      "已读取'3.3.坚持抗战、团结、进步，系统阐述新民主主义理论.txt'文件内容\n",
      "已读取'3.4.加强根据地建设，开展整风运动.txt'文件内容\n",
      "已读取'3.5.党的七大确立毛泽东思想为全党指导思想，抗日战争取得最后胜利.txt'文件内容\n",
      "第3章词频统计文件已保存\n",
      "开始处理共产党简史第4章的文本内容\n",
      "已读取'4.1.重庆谈判和争取和平民主的努力.txt'文件内容\n",
      "已读取'4.2.以自卫战争粉碎国民党的军事进攻和开展第二条战线的斗争.txt'文件内容\n",
      "已读取'4.3.人民解放军转入战略进攻和土地制度的改革.txt'文件内容\n",
      "已读取'4.4.伟大的战略决战和国民党反动统治的覆灭.txt'文件内容\n",
      "已读取'4.5.党的七届二中全会和人民政协的召开.txt'文件内容\n",
      "第4章词频统计文件已保存\n",
      "开始处理共产党简史第5章的文本内容\n",
      "已读取'5.1.新中国的诞生，人民民主政权在全国范围的建立和巩固.txt'文件内容\n",
      "已读取'5.2.新民主主义改革和建设的全面展开，国民经济的恢复.txt'文件内容\n",
      "已读取'5.3.党在过渡时期总路线的提出和有计划经济建设的开始.txt'文件内容\n",
      "已读取'5.4.社会主义改造的基本完成和社会主义制度的初步建立.txt'文件内容\n",
      "第5章词频统计文件已保存\n",
      "开始处理共产党简史第6章的文本内容\n",
      "已读取'6.1.党的八大和探索建设社会主义道路的良好开端.txt'文件内容\n",
      "已读取'6.2.正确处理人民内部矛盾理论的提出和全党整风.txt'文件内容\n",
      "已读取'6.3.“大跃进”、人民公社化运动和纠“左”过程中的曲折.txt'文件内容\n",
      "已读取'6.4.“调整、巩固、充实、提高”方针的提出和政治上“左”的错误的发展.txt'文件内容\n",
      "已读取'6.5.国民经济调整任务的完成和十年建设成就.txt'文件内容\n",
      "第6章词频统计文件已保存\n",
      "开始处理共产党简史第7章的文本内容\n",
      "已读取'7.1.“文化大革命”的发动和全面内乱.txt'文件内容\n",
      "已读取'7.2.林彪集团的覆灭和纠正极左思潮的努力.txt'文件内容\n",
      "已读取'7.3.同“四人帮”的斗争和1975年的全面整顿.txt'文件内容\n",
      "已读取'7.4.粉碎江青集团的胜利.txt'文件内容\n",
      "第7章词频统计文件已保存\n",
      "开始处理共产党简史第8章的文本内容\n",
      "已读取'8.1.在徘徊中前进和真理标准问题讨论.txt'文件内容\n",
      "已读取'8.2.建国后党和国家历史发展的伟大转折.txt'文件内容\n",
      "已读取'8.3.经济调整和改革开放的起步.txt'文件内容\n",
      "已读取'8.4.拨乱反正任务胜利完成.txt'文件内容\n",
      "第8章词频统计文件已保存\n",
      "开始处理共产党简史第9章的文本内容\n",
      "已读取'9.1.党的十二大和全面改革纲领的制定.txt'文件内容\n",
      "已读取'9.2.对外开放格局的初步形成和对外关系的调整.txt'文件内容\n",
      "已读取'9.3.党的十三大和社会主义初级阶段的理论与基本路线.txt'文件内容\n",
      "已读取'9.4.经济上的治理整顿和经受国内外政治风波的考验.txt'文件内容\n",
      "第9章词频统计文件已保存\n",
      "开始处理共产党简史第10章的文本内容\n",
      "已读取'10.1.邓小平视察南方和党的十四大.txt'文件内容\n",
      "已读取'10.2.建立社会主义市场经济体制过程中宏观调控的成功实施.txt'文件内容\n",
      "已读取'10.3.“一国两制”构想和香港、澳门回归祖国.txt'文件内容\n",
      "已读取'10.4.党的十五大和跨世纪发展战略.txt'文件内容\n",
      "已读取'10.5.按照“三个代表”要求，推进党的建设新的伟大工程.txt'文件内容\n",
      "已读取'10.6.高举邓小平理论旗帜，把建设有中国特色社会主义事业推向前进.txt'文件内容\n",
      "第10章词频统计文件已保存\n"
     ]
    }
   ],
   "source": [
    "#写一个循环，分别读取每一章的内容（每一章有多节），并进行分词停用词频统计\n",
    "for chapter in range(1,11):\n",
    "    print('开始处理共产党简史第%i章的文本内容'%chapter)\n",
    "    dataset = [] # 存储文本文件\n",
    "    for filepath in fileslist:\n",
    "        if filepath.split('.')[0] == str(chapter):\n",
    "            print('已读取%r文件内容'%filepath)\n",
    "            fullfilepath = os.path.join(dirpath, filepath)\n",
    "            fn =  open(fullfilepath, \"r\", encoding='utf-8') # 打开文件\n",
    "            data = fn.read()                                # 读取文件\n",
    "            dataset.append(data)                    # 将文件添加到列表中\n",
    "            fn.close()                              #关闭文件\n",
    "    dataset = ','.join(dataset)#转化为非数组类型\n",
    "    # 文本预处理\n",
    "    pattern = re.compile(u'\\t|\\n|\\.|-|:|;|\\)|\\(|\\?|\"|\\u3000') # 定义正则表达式匹配模式\n",
    "    string_data = re.sub(pattern, '', dataset) # 将符合模式的字符去除\n",
    "    # 文本分词\n",
    "    seg_list_exact = jieba.cut(string_data, cut_all = False) # 精确模式分词\n",
    "    object_list = []\n",
    "    stopwords = stopwordslist() #读取停用词\n",
    "    for word in seg_list_exact: # 循环读出每个分词\n",
    "        if word not in stopwords: # 如果不在去除词库中\n",
    "            object_list.append(word) # 分词追加到列表\n",
    "    # 词频统计\n",
    "    word_counts = collections.Counter(object_list) # 对分词做词频统计\n",
    "    df = pd.DataFrame.from_dict(data = dict(word_counts),orient='index')\n",
    "    df.to_csv('第%i章词频统计.csv'%chapter,encoding='gbk',header=False)\n",
    "    print('第%i章词频统计文件已保存'%chapter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 采用情感词表对每章的情绪进行评价（参考情感词汇本体），给出你的简单分析"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 先尝试第一章"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# 尝试将第一章的词频数据，与情绪词汇库merge起来\n",
    "sent = pd.read_csv(r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\codedemo\\第1章词频统计.csv',encoding='gbk',header=None,names=['words','frequency'])\n",
    "dict = pd.read_excel(r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\2022-06-机器学习期末大作业\\情感词汇本体\\情感词汇本体.xlsx')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "mergedf1 = pd.merge(sent,dict.drop(columns=['词义数','词义序号','词性种类','Unnamed: 10','Unnamed: 11']),how='inner',left_on='words',right_on='词语')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "  words  frequency    词语 情感分类  强度  极性 辅助情感分类  强度.1  极性.1\n0    发展         27    发展   PH   3   0    NaN   NaN   NaN\n1    勤劳          1    勤劳   PH   5   1    NaN   NaN   NaN\n2    智慧          1    智慧   PH   7   1     PA   3.0   1.0\n3    创造          2    创造   PH   3   0    NaN   NaN   NaN\n4  独领风骚          1  独领风骚   PH   7   1    NaN   NaN   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>frequency</th>\n      <th>词语</th>\n      <th>情感分类</th>\n      <th>强度</th>\n      <th>极性</th>\n      <th>辅助情感分类</th>\n      <th>强度.1</th>\n      <th>极性.1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>发展</td>\n      <td>27</td>\n      <td>发展</td>\n      <td>PH</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>勤劳</td>\n      <td>1</td>\n      <td>勤劳</td>\n      <td>PH</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>智慧</td>\n      <td>1</td>\n      <td>智慧</td>\n      <td>PH</td>\n      <td>7</td>\n      <td>1</td>\n      <td>PA</td>\n      <td>3.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>创造</td>\n      <td>2</td>\n      <td>创造</td>\n      <td>PH</td>\n      <td>3</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>独领风骚</td>\n      <td>1</td>\n      <td>独领风骚</td>\n      <td>PH</td>\n      <td>7</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedf1.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "mergedf1['sorce'] = mergedf1.frequency*mergedf1.强度 #使用频数*强度作为情感得分\n",
    "mergedf1['sorce1'] = mergedf1.frequency*mergedf1['强度.1'] #辅助情感同样使用频数*强度作为情感得分\n",
    "df2 = mergedf1[['辅助情感分类','极性.1','sorce1']].dropna() #分离辅助情感，删除空值\n",
    "df2.columns=['情感分类','极性','sorce'] #重命名\n",
    "df3 = pd.concat([mergedf1[['情感分类','极性','sorce']],df2],axis=0,ignore_index=True) #拼接主情感和辅助情感得分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "情感分类\nNB      95.0\nNC      70.0\nND     213.0\nNE     208.0\nNG       7.0\nNI       7.0\nNJ      21.0\nNL      32.0\nNN     809.0\nPA     259.0\nPB      77.0\nPC      26.0\nPD     118.0\nPE      24.0\nPF       2.0\nPG     180.0\nPH    1050.0\nPK      56.0\nName: sorce, dtype: float64"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#输出情感得分\n",
    "df3.groupby('情感分类')['sorce'].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "极性\n0.0    102\n1.0    120\n2.0    114\nName: 情感分类, dtype: int64"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.groupby('极性')['情感分类'].count() #输出褒贬含义情感出现的次数，0代表中性，1代表褒义，2代表贬义，3代表兼有褒贬两性"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 遍历每一章"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始分析共产党简史第1章的情感\n",
      "开始分析共产党简史第2章的情感\n",
      "开始分析共产党简史第3章的情感\n",
      "开始分析共产党简史第4章的情感\n",
      "开始分析共产党简史第5章的情感\n",
      "开始分析共产党简史第6章的情感\n",
      "开始分析共产党简史第7章的情感\n",
      "开始分析共产党简史第8章的情感\n",
      "开始分析共产党简史第9章的情感\n",
      "开始分析共产党简史第10章的情感\n"
     ]
    }
   ],
   "source": [
    "outputdf1 = pd.DataFrame() #存储每章的情感得分\n",
    "outputdf2 = pd.DataFrame() #存储每章的褒贬含义\n",
    "dict = pd.read_excel(r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\2022-06-机器学习期末大作业\\情感词汇本体\\情感词汇本体.xlsx')\n",
    "for chapter in range(1,11):\n",
    "    print('开始分析共产党简史第%i章的情感'%chapter)\n",
    "    sent = pd.read_csv(r'C:\\Users\\欧玮杰\\Desktop\\咸鱼业务\\2022-6-2机器学习期末\\codedemo\\第%i章词频统计.csv'%chapter,encoding='gbk',header=None,names=['words','frequency'])\n",
    "    mergedf1 = pd.merge(sent,dict.drop(columns=['词义数','词义序号','词性种类','Unnamed: 10','Unnamed: 11']),how='inner',left_on='words',right_on='词语')\n",
    "    mergedf1['sorce'] = mergedf1.frequency*mergedf1.强度 #使用频数*强度作为情感得分\n",
    "    mergedf1['sorce1'] = mergedf1.frequency*mergedf1['强度.1'] #辅助情感同样使用频数*强度作为情感得分\n",
    "    df2 = mergedf1[['辅助情感分类','极性.1','sorce1']].dropna() #分离辅助情感，删除空值\n",
    "    df2.columns=['情感分类','极性','sorce'] #重命名\n",
    "    df3 = pd.concat([mergedf1[['情感分类','极性','sorce']],df2],axis=0,ignore_index=True) #拼接主情感和辅助情感得分\n",
    "    #输出情感得分\n",
    "    outputdf1 = pd.concat([outputdf1,df3.groupby('情感分类')['sorce'].sum()],axis=1)\n",
    "    outputdf2 = pd.concat([outputdf2,df3.groupby('极性')['情感分类'].count()],axis=1)\n",
    "outputdf1.columns = ['第%i章情感得分'%i for i in range(1, 11)] #重命名列\n",
    "outputdf2.columns = ['第%i章褒贬含义次数'%i for i in range(1, 11)] #重命名列"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "    第1章情感得分  第2章情感得分  第3章情感得分  第4章情感得分  第5章情感得分  第6章情感得分  第7章情感得分  第8章情感得分  \\\nNB     95.0     78.0    149.0     92.0     29.0     21.0    151.0     43.0   \nNC     70.0    154.0     81.0     21.0     34.0      6.0     81.0     22.0   \nND    213.0    212.0    271.0    267.0    140.0     56.0    286.0    101.0   \nNE    208.0    109.0     87.0    124.0     60.0    106.0    147.0    112.0   \nNG      7.0      NaN      7.0      NaN      5.0      NaN      NaN      NaN   \nNI      7.0     47.0      8.0     59.0     56.0     76.0     23.0     25.0   \nNJ     21.0     35.0     24.0     21.0      5.0      5.0     21.0     45.0   \nNL     32.0      5.0      NaN      NaN      5.0     15.0     21.0     26.0   \nNN    809.0    442.0    538.0    397.0    388.0    338.0   1197.0    554.0   \nPA    259.0    202.0    306.0    339.0    423.0    393.0    209.0    249.0   \nPB     77.0     46.0     61.0    107.0     59.0     61.0     62.0     58.0   \nPC     26.0     11.0     21.0      6.0      3.0      8.0      8.0      NaN   \nPD    118.0    190.0    281.0    150.0    100.0    143.0    221.0    140.0   \nPE     24.0     33.0      7.0    117.0     57.0     34.0     33.0    109.0   \nPF      2.0      1.0      NaN      4.0      NaN      NaN     10.0      7.0   \nPG    180.0    198.0    217.0    138.0    287.0    230.0    172.0    359.0   \nPH   1050.0    948.0   1261.0    843.0   1069.0   1149.0    671.0   1267.0   \nPK     56.0    134.0     86.0    103.0      5.0     37.0     39.0     67.0   \nNH      NaN      NaN      NaN      NaN      NaN     33.0      NaN     14.0   \nNK      NaN      NaN      NaN      NaN      NaN      NaN      1.0      NaN   \n\n    第9章情感得分  第10章情感得分  \nNB     19.0      59.0  \nNC     56.0      27.0  \nND     21.0      69.0  \nNE     63.0      42.0  \nNG      5.0       NaN  \nNI     46.0      18.0  \nNJ     18.0      11.0  \nNL      8.0      22.0  \nNN    140.0     154.0  \nPA    264.0     427.0  \nPB     26.0      59.0  \nPC     18.0       8.0  \nPD    136.0     234.0  \nPE     57.0      72.0  \nPF      NaN      18.0  \nPG    203.0     327.0  \nPH   1459.0    1987.0  \nPK     48.0      60.0  \nNH     14.0       NaN  \nNK      NaN       NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>第1章情感得分</th>\n      <th>第2章情感得分</th>\n      <th>第3章情感得分</th>\n      <th>第4章情感得分</th>\n      <th>第5章情感得分</th>\n      <th>第6章情感得分</th>\n      <th>第7章情感得分</th>\n      <th>第8章情感得分</th>\n      <th>第9章情感得分</th>\n      <th>第10章情感得分</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>NB</th>\n      <td>95.0</td>\n      <td>78.0</td>\n      <td>149.0</td>\n      <td>92.0</td>\n      <td>29.0</td>\n      <td>21.0</td>\n      <td>151.0</td>\n      <td>43.0</td>\n      <td>19.0</td>\n      <td>59.0</td>\n    </tr>\n    <tr>\n      <th>NC</th>\n      <td>70.0</td>\n      <td>154.0</td>\n      <td>81.0</td>\n      <td>21.0</td>\n      <td>34.0</td>\n      <td>6.0</td>\n      <td>81.0</td>\n      <td>22.0</td>\n      <td>56.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>ND</th>\n      <td>213.0</td>\n      <td>212.0</td>\n      <td>271.0</td>\n      <td>267.0</td>\n      <td>140.0</td>\n      <td>56.0</td>\n      <td>286.0</td>\n      <td>101.0</td>\n      <td>21.0</td>\n      <td>69.0</td>\n    </tr>\n    <tr>\n      <th>NE</th>\n      <td>208.0</td>\n      <td>109.0</td>\n      <td>87.0</td>\n      <td>124.0</td>\n      <td>60.0</td>\n      <td>106.0</td>\n      <td>147.0</td>\n      <td>112.0</td>\n      <td>63.0</td>\n      <td>42.0</td>\n    </tr>\n    <tr>\n      <th>NG</th>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>NI</th>\n      <td>7.0</td>\n      <td>47.0</td>\n      <td>8.0</td>\n      <td>59.0</td>\n      <td>56.0</td>\n      <td>76.0</td>\n      <td>23.0</td>\n      <td>25.0</td>\n      <td>46.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>NJ</th>\n      <td>21.0</td>\n      <td>35.0</td>\n      <td>24.0</td>\n      <td>21.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>21.0</td>\n      <td>45.0</td>\n      <td>18.0</td>\n      <td>11.0</td>\n    </tr>\n    <tr>\n      <th>NL</th>\n      <td>32.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>15.0</td>\n      <td>21.0</td>\n      <td>26.0</td>\n      <td>8.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>NN</th>\n      <td>809.0</td>\n      <td>442.0</td>\n      <td>538.0</td>\n      <td>397.0</td>\n      <td>388.0</td>\n      <td>338.0</td>\n      <td>1197.0</td>\n      <td>554.0</td>\n      <td>140.0</td>\n      <td>154.0</td>\n    </tr>\n    <tr>\n      <th>PA</th>\n      <td>259.0</td>\n      <td>202.0</td>\n      <td>306.0</td>\n      <td>339.0</td>\n      <td>423.0</td>\n      <td>393.0</td>\n      <td>209.0</td>\n      <td>249.0</td>\n      <td>264.0</td>\n      <td>427.0</td>\n    </tr>\n    <tr>\n      <th>PB</th>\n      <td>77.0</td>\n      <td>46.0</td>\n      <td>61.0</td>\n      <td>107.0</td>\n      <td>59.0</td>\n      <td>61.0</td>\n      <td>62.0</td>\n      <td>58.0</td>\n      <td>26.0</td>\n      <td>59.0</td>\n    </tr>\n    <tr>\n      <th>PC</th>\n      <td>26.0</td>\n      <td>11.0</td>\n      <td>21.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>PD</th>\n      <td>118.0</td>\n      <td>190.0</td>\n      <td>281.0</td>\n      <td>150.0</td>\n      <td>100.0</td>\n      <td>143.0</td>\n      <td>221.0</td>\n      <td>140.0</td>\n      <td>136.0</td>\n      <td>234.0</td>\n    </tr>\n    <tr>\n      <th>PE</th>\n      <td>24.0</td>\n      <td>33.0</td>\n      <td>7.0</td>\n      <td>117.0</td>\n      <td>57.0</td>\n      <td>34.0</td>\n      <td>33.0</td>\n      <td>109.0</td>\n      <td>57.0</td>\n      <td>72.0</td>\n    </tr>\n    <tr>\n      <th>PF</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>NaN</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>PG</th>\n      <td>180.0</td>\n      <td>198.0</td>\n      <td>217.0</td>\n      <td>138.0</td>\n      <td>287.0</td>\n      <td>230.0</td>\n      <td>172.0</td>\n      <td>359.0</td>\n      <td>203.0</td>\n      <td>327.0</td>\n    </tr>\n    <tr>\n      <th>PH</th>\n      <td>1050.0</td>\n      <td>948.0</td>\n      <td>1261.0</td>\n      <td>843.0</td>\n      <td>1069.0</td>\n      <td>1149.0</td>\n      <td>671.0</td>\n      <td>1267.0</td>\n      <td>1459.0</td>\n      <td>1987.0</td>\n    </tr>\n    <tr>\n      <th>PK</th>\n      <td>56.0</td>\n      <td>134.0</td>\n      <td>86.0</td>\n      <td>103.0</td>\n      <td>5.0</td>\n      <td>37.0</td>\n      <td>39.0</td>\n      <td>67.0</td>\n      <td>48.0</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>NH</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>33.0</td>\n      <td>NaN</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>NK</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "     第1章褒贬含义次数  第2章褒贬含义次数  第3章褒贬含义次数  第4章褒贬含义次数  第5章褒贬含义次数  第6章褒贬含义次数  \\\n0.0        102         96         91         88         73         83   \n1.0        120        101        131        112        136        109   \n2.0        114        109         92         97        101         52   \n\n     第7章褒贬含义次数  第8章褒贬含义次数  第9章褒贬含义次数  第10章褒贬含义次数  \n0.0         91         87         75          79  \n1.0         98        117        126         161  \n2.0        111         74         48          43  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>第1章褒贬含义次数</th>\n      <th>第2章褒贬含义次数</th>\n      <th>第3章褒贬含义次数</th>\n      <th>第4章褒贬含义次数</th>\n      <th>第5章褒贬含义次数</th>\n      <th>第6章褒贬含义次数</th>\n      <th>第7章褒贬含义次数</th>\n      <th>第8章褒贬含义次数</th>\n      <th>第9章褒贬含义次数</th>\n      <th>第10章褒贬含义次数</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.0</th>\n      <td>102</td>\n      <td>96</td>\n      <td>91</td>\n      <td>88</td>\n      <td>73</td>\n      <td>83</td>\n      <td>91</td>\n      <td>87</td>\n      <td>75</td>\n      <td>79</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>120</td>\n      <td>101</td>\n      <td>131</td>\n      <td>112</td>\n      <td>136</td>\n      <td>109</td>\n      <td>98</td>\n      <td>117</td>\n      <td>126</td>\n      <td>161</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <td>114</td>\n      <td>109</td>\n      <td>92</td>\n      <td>97</td>\n      <td>101</td>\n      <td>52</td>\n      <td>111</td>\n      <td>74</td>\n      <td>48</td>\n      <td>43</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputdf2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}